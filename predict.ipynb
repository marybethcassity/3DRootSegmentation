{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d489ad2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import open3d as o3d\n",
    "from pycocotools.coco import COCO\n",
    "import json\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977ca675",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca9ca6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import detectron2\n",
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827e861e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may need to restart your runtime prior to this, to let your installation take effect\n",
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.data.catalog import DatasetCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e18d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_to_contour(mask):\n",
    "    contours, _ = cv2.findContours(\n",
    "        mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE\n",
    "    )\n",
    "    return contours\n",
    "\n",
    "def get_random_color():\n",
    "    return [\"#\" + \"\".join([random.choice(\"ABCDEF0123456789\") for _ in range(6)])][\n",
    "        0\n",
    "    ].lower()\n",
    "\n",
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49513694",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data.datasets import register_coco_instances\n",
    "register_coco_instances(\"my_dataset_train\", {}, r\"\", r\"\") #paths to json and images\n",
    "register_coco_instances(\"my_dataset_test\", {}, r\"\", r\"\") #paths to json and images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d68db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Metadata: The Metadata instance associated with this name,\n",
    "#or create an empty one if none is available.\n",
    "train_metadata = MetadataCatalog.get(\"my_dataset_train\")\n",
    "\n",
    "#list[dict]: dataset annotations.0\n",
    "train_dict = DatasetCatalog.get(\"my_dataset_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3edaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "\n",
    "from detectron2.evaluation.coco_evaluation import COCOEvaluator\n",
    "import os\n",
    "from detectron2.config import get_cfg\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml\")) #choose backbone\n",
    "cfg.DATASETS.TRAIN = (\"my_dataset_train\",)\n",
    "cfg.DATASETS.TEST = (\"my_dataset_test\",)\n",
    "\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml\")\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.001\n",
    "\n",
    "cfg.SOLVER.WARMUP_ITERS = 200\n",
    "cfg.SOLVER.MAX_ITER = 500 \n",
    "cfg.SOLVER.GAMMA = 0.05\n",
    "#cfg.DATASETS.TEST = ()\n",
    "#cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.80\n",
    "\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 64 \n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1 \n",
    "\n",
    "cfg.TEST.EVAL_PERIOD = 500\n",
    "\n",
    "#cfg.PYTORCH_CUDA_ALLOC_CONF\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da77f6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.MODEL.WEIGHTS = os.path.join(r\"\") #path to trained model\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.80\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aed2e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_path = r\"\" #path to images \n",
    "\n",
    "overlap = 100 #set overlap and image size\n",
    "size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf75eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = re.compile(r'(\\d+)')\n",
    "\n",
    "def numericalSort(value):\n",
    "    parts = numbers.split(value)\n",
    "    parts[1::2] = map(int, parts[1::2])\n",
    "    return parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99909d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORY_TEMPLATE = {\n",
    "    \"id\": 1,\n",
    "    \"name\": \"person\",\n",
    "    \"supercategory\": None,\n",
    "    \"metadata\": {},\n",
    "    \"color\": \"#69db90\",\n",
    "}\n",
    "\n",
    "IMAGES_TEMPLATE = {\n",
    "    \"id\": 0,\n",
    "    \"width\": 530,\n",
    "    \"height\": 301,\n",
    "    \"file_name\": \"\",\n",
    "    \"path\": \"\",\n",
    "    \"license\": None,\n",
    "    \"fickr_url\": None,\n",
    "    \"coco_url\": None,\n",
    "    \"date_captured\": None,\n",
    "    \"metadata\": {},\n",
    "}\n",
    "\n",
    "ANNOTATIONS_TEMPLATE = {\n",
    "    \"id\": 1,\n",
    "    \"image_id\": 0,\n",
    "    \"category_id\": 1,\n",
    "    \"width\": 530,\n",
    "    \"height\": 301,\n",
    "    \"area\": 59767,\n",
    "    \"segmentation\": [[221, 7, 220, 8, 215, 8]],\n",
    "    \"bbox\": [150, 7, 253, 286],\n",
    "    \"metadata\": {},\n",
    "    \"color\": \"#bc07ae\",\n",
    "    \"iscrowd\": 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f847c770",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function was for filtering predictions by texture features, I found it did not improve results\n",
    "\n",
    "def get_pred(imPath, mask):\n",
    "    \n",
    "    contours_filtered = []\n",
    "    \n",
    "    im = cv2.imread(imPath,cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    im_masked = (mask*im).clip(0,255).astype(np.uint8)\n",
    "    #plt.imshow(im_masked)\n",
    "    \n",
    "    #shape = mask.shape\n",
    "    #mask3 = np.empty([shape[0],shape[1],3])\n",
    "\n",
    "    #mask3[:,:,0] = mask\n",
    "    #mask3[:,:,1] = mask\n",
    "    #mask3[:,:,2] = mask\n",
    "\n",
    "    #im_masked = (mask3*im).clip(0,255).astype(np.uint8)\n",
    "    #plt.imshow(im_masked)\n",
    "    out_list = []\n",
    "    \n",
    "    mask = mask.astype(np.uint8)\n",
    "    contours = mask_to_contour(mask)\n",
    "    \n",
    "    #if(len(contours)>0):\n",
    "    #    for contour in contours:\n",
    "    #        X,Y,W,H = cv2.boundingRect(contour)\n",
    "    #        predicted = im_masked[Y:Y+H, X:X+W]\n",
    "    #        desc = LocalBinaryPatterns(12, 4)\n",
    "    #        hist, bins, lbp = desc.describe(predicted)\n",
    "    #        hist = hist.flatten()\n",
    "    #        plt.imshow(predicted)\n",
    "    #        out = hist \n",
    "    #        out = np.ndarray.tolist(out)\n",
    "    #        out_list.append(out)\n",
    "        \n",
    "    #    data = pd.DataFrame(out_list, columns = [\"lbp\",\"lbp.1\",\"lbp.2\",\"lbp.3\",\"lbp.4\",\"lbp.5\",\"lbp.6\",\"lbp.7\",\"lbp.8\",\"lbp.9\",\"lbp.10\",\"lbp.11\",\"lbp.12\",\"lbp.13\"])\n",
    "    #    values = model.predict(data)\n",
    "    \n",
    "    #    for x in range(len(contours)):\n",
    "    #        if (values[x] == 1):\n",
    "    #            contours_filtered.append(contours[x])\n",
    "    \n",
    "    return contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885bab1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_anns(contours_filtered):\n",
    "    \n",
    "    global IM_NUM\n",
    "    global ANN_NUM\n",
    "    \n",
    "    annotations = []\n",
    "    \n",
    "    for contour in contours_filtered:\n",
    "        \n",
    "        bbox = cv2.boundingRect(contour)\n",
    "        segmentation = np.array(contour).flatten().tolist()\n",
    "        \n",
    "        \n",
    "        if (len(segmentation) == 4):\n",
    "            segmentation.append(segmentation[-2])\n",
    "            segmentation.append(segmentation[-2])\n",
    "            print(segmentation)\n",
    "        \n",
    "        if (len(segmentation) < 4):\n",
    "            segmentation.append(segmentation[-2])\n",
    "            segmentation.append(segmentation[-2])\n",
    "            segmentation.append(segmentation[-2])\n",
    "            segmentation.append(segmentation[-2])\n",
    "            print(segmentation)\n",
    "            \n",
    "        \n",
    "        annotation = dotdict(ANNOTATIONS_TEMPLATE)\n",
    "        annotation.id = ANN_NUM\n",
    "        annotation.image_id = IM_NUM\n",
    "        annotation.category_id = 1\n",
    "        annotation.width = bbox[2]\n",
    "        annotation.height = bbox[3]\n",
    "        annotation.area = cv2.contourArea(contour)\n",
    "        annotation.segmentation = [segmentation]\n",
    "        annotation.bbox = [bbox[0],bbox[1],bbox[2],bbox[3]]\n",
    "        annotation.color = get_random_color()\n",
    "        \n",
    "        annotations += [annotation]\n",
    "        \n",
    "        ANN_NUM = ANN_NUM + 1\n",
    "        \n",
    "    return  annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cd1fb6",
   "metadata": {},
   "source": [
    "# Predict on one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1826b2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict1im(imagePath):\n",
    "    img = cv2.imread(imagePath)\n",
    "\n",
    "    height, width, _ = img.shape\n",
    "    height_new = math.ceil(height/size) * size\n",
    "    height_scale = height_new/height \n",
    "    delta_y= height - height_new\n",
    "    \n",
    "    width_new = math.ceil(width/size) * size\n",
    "    width_scale = width_new/ width\n",
    "    delta_x = width - width_new\n",
    "    \n",
    "    resized_im = cv2.resize(img, (width_new, height_new), cv2.INTER_LINEAR)\n",
    "    \n",
    "    num_tiles_i = height_new/size\n",
    "    num_tiles_j = width_new/size\n",
    "        #print(\"num_tiles_i:\", num_tiles_i)\n",
    "        #print(\"num_tiles_j:\", num_tiles_j)\n",
    "    \n",
    "    total_tiles = num_tiles_i * num_tiles_j\n",
    "    \n",
    "    tile_stack = np.zeros((height_new, width_new, int(total_tiles)))\n",
    "    \n",
    "    tile_num = 0\n",
    "    \n",
    "    for i in range(height_new//size):\n",
    "        for j in range(width_new//size):\n",
    "            \n",
    "            if(i<num_tiles_i-1):\n",
    "                overlap_i = overlap\n",
    "            else:\n",
    "                overlap_i = 0\n",
    "            \n",
    "            if(j<num_tiles_j-1):\n",
    "                overlap_j = overlap\n",
    "            else:\n",
    "                overlap_j = 0\n",
    "            \n",
    "            tile = resized_im[i*(size) : (i+1)*size + overlap_i, j*size : (j+1)*size + overlap_j, :]\n",
    "            #plt.imshow(tile)\n",
    "            \n",
    "            outputs = predictor(tile)\n",
    "            \n",
    "            v = Visualizer(tile[:, :, ::-1],\n",
    "                    metadata=train_metadata, \n",
    "                    scale=0.5, \n",
    "            )\n",
    "            \n",
    "            \n",
    "            instances = outputs[\"instances\"]\n",
    "            \n",
    "            pred_masks =  instances.pred_masks\n",
    "            mask = np.full((pred_masks.shape[1], pred_masks.shape[2]), False)\n",
    "            #print(mask)\n",
    "            \n",
    "            for m in pred_masks:\n",
    "                mask = mask | m.cpu().numpy()\n",
    "                \n",
    "            mask = mask.astype(np.uint8)*255\n",
    "            \n",
    "            \n",
    "            tile_stack[i*(size) : (i+1)*size + overlap_i, j*size : (j+1)*size + overlap_j, tile_num] = mask\n",
    "            #print(tile_num)\n",
    "            #print(\"overlap i:\", overlap_i)\n",
    "            #print(\"overlap j:\", overlap_j)\n",
    "            \n",
    "            #print(\"i:\", i)\n",
    "            #print(\"j:\", j)\n",
    "    \n",
    "            tile_num = tile_num + 1 \n",
    "    \n",
    "    \n",
    "    image_pred = np.sum(tile_stack,axis=2)\n",
    "    image_pred = image_pred.clip(min = 0, max = 255)\n",
    "    image_pred_resized = cv2.resize(image_pred, (width, height), cv2.INTER_LINEAR) #resize it back down so dimensions will match  \n",
    "    \n",
    "    filtered_contours = get_pred(imagePath, image_pred_resized)\n",
    "\n",
    "    cv2.drawContours(img, filtered_contours, -1, (0,255,0), 10)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39b3d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_path = r\"\" #path to images\n",
    "imPath = os.path.join(im_path,'') #image name\n",
    "\n",
    "im1 = predict1im(imPath)\n",
    "plt.imshow(im1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42d6abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_path = r\"\" #path to images\n",
    "imPath2 = os.path.join(im_path,'') #image name\n",
    "\n",
    "im2 = predict1im(imPath2)\n",
    "plt.imshow(im2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89269791",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(imPath)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3d5e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = predictor(cv2.imread(imPath))  \n",
    "v = Visualizer(im1[:, :, ::-1],metadata=train_metadata, scale=0.5)\n",
    "out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "\n",
    "plt.imshow(out.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec8bac6",
   "metadata": {},
   "source": [
    "# Predict on all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd6c4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = []\n",
    "\n",
    "category = dotdict(CATEGORY_TEMPLATE)\n",
    "category.id = 1\n",
    "category.name = 'root'\n",
    "category.color = get_random_color()\n",
    "\n",
    "categories += [category]\n",
    "\n",
    "annotations = []\n",
    "images = []\n",
    "IM_NUM = 1\n",
    "ANN_NUM = 1 \n",
    "\n",
    "\n",
    "for imPath in sorted(glob.glob(im_path + '/*.png'), key = numericalSort):\n",
    "     \n",
    "    #plt.clf()\n",
    "    \n",
    "    #print(\"imPath:\",imPath)\n",
    "    \n",
    "    basename = os.path.basename(imPath)\n",
    "    \n",
    "    #print(\"basename:\",basename)\n",
    "    \n",
    "    filename = basename.split(\".\")[0]\n",
    "    \n",
    "    #print(\"filename:\",filename)\n",
    "    \n",
    "    img = cv2.imread(imPath)\n",
    "    height, width, _ = img.shape\n",
    "    height_new = math.ceil(height/size) * size\n",
    "    height_scale = height_new/height \n",
    "    delta_y= height - height_new\n",
    "    \n",
    "    width_new = math.ceil(width/size) * size\n",
    "    width_scale = width_new/ width\n",
    "    delta_x = width - width_new\n",
    "    \n",
    "    resized_im = cv2.resize(img, (width_new, height_new), cv2.INTER_LINEAR)\n",
    "    \n",
    "    num_tiles_i = height_new/size\n",
    "    num_tiles_j = width_new/size\n",
    "    #print(\"num_tiles_i:\", num_tiles_i)\n",
    "    #print(\"num_tiles_j:\", num_tiles_j)\n",
    "    \n",
    "    total_tiles = num_tiles_i * num_tiles_j\n",
    "    \n",
    "    tile_stack = np.zeros((height_new, width_new, int(total_tiles)))\n",
    "    \n",
    "    tile_num = 0\n",
    "    \n",
    "    for i in range(height_new//size):\n",
    "        for j in range(width_new//size):\n",
    "            \n",
    "            if(i<num_tiles_i-1):\n",
    "                overlap_i = overlap\n",
    "            else:\n",
    "                overlap_i = 0\n",
    "            \n",
    "            if(j<num_tiles_j-1):\n",
    "                overlap_j = overlap\n",
    "            else:\n",
    "                overlap_j = 0\n",
    "            \n",
    "            tile = resized_im[i*(size) : (i+1)*size + overlap_i, j*size : (j+1)*size + overlap_j, :]\n",
    "            #plt.imshow(tile)\n",
    "            \n",
    "            outputs = predictor(tile)\n",
    "            \n",
    "            v = Visualizer(tile[:, :, ::-1],\n",
    "                   metadata=train_metadata, \n",
    "                   scale=0.5, \n",
    "            )\n",
    "            \n",
    "            \n",
    "            instances = outputs[\"instances\"]\n",
    "            \n",
    "            pred_masks =  instances.pred_masks\n",
    "            mask = np.full((pred_masks.shape[1], pred_masks.shape[2]), False)\n",
    "            #print(mask)\n",
    "            \n",
    "            for m in pred_masks:\n",
    "                mask = mask | m.cpu().numpy()\n",
    "                \n",
    "            mask = mask.astype(np.uint8)*255\n",
    "            \n",
    "            \n",
    "            tile_stack[i*(size) : (i+1)*size + overlap_i, j*size : (j+1)*size + overlap_j, tile_num] = mask\n",
    "            #print(tile_num)\n",
    "            #print(\"overlap i:\", overlap_i)\n",
    "            #print(\"overlap j:\", overlap_j)\n",
    "            \n",
    "            #print(\"i:\", i)\n",
    "            #print(\"j:\", j)\n",
    "    \n",
    "            tile_num = tile_num + 1 \n",
    "    \n",
    "    \n",
    "    image_pred = np.sum(tile_stack,axis=2)\n",
    "    image_pred = image_pred.clip(min = 0, max = 255)\n",
    "    image_pred_resized = cv2.resize(image_pred, (width, height), cv2.INTER_LINEAR) #resize it back down so dimensions will match\n",
    "    \n",
    "    #print(image_pred_resized.shape)\n",
    "    \n",
    "    filtered_contours = get_pred(imPath, image_pred_resized)\n",
    "    \n",
    "    image = dotdict(IMAGES_TEMPLATE)\n",
    "    image.width = image_pred_resized.shape[1]\n",
    "    image.height = image_pred_resized.shape[0]\n",
    "    image.file_name = basename\n",
    "    image.id = IM_NUM\n",
    "    images += [image]\n",
    "    \n",
    "    if(len(filtered_contours)>0):\n",
    "        anns = get_anns(filtered_contours)\n",
    "        annotations += anns\n",
    "    \n",
    "    IM_NUM = IM_NUM + 1\n",
    "    #print(IM_NUM) #print the image number if you want to keep track of progress\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251b0942",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco = {\"annotations\": annotations, \"categories\": categories, \"images\": images}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3106b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"\", \"w\") as outfile: #path to predictions json\n",
    "    json.dump(coco, outfile)\n",
    "outfile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
